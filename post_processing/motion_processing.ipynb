{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, fnmatch\n",
    "import numpy as np\n",
    "from scipy.stats import iqr\n",
    "from numpy import percentile\n",
    "\n",
    "def locate(pattern, root=os.curdir):\n",
    "    '''Locate all files matching supplied filename pattern in and below\n",
    "    supplied root directory.'''\n",
    "    for path, dirs, files in os.walk(os.path.abspath(root)):\n",
    "        for filename in fnmatch.filter(files, pattern):\n",
    "            return os.path.join(path, filename)\n",
    "            #yield os.path.join(path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/net/holynfs01/srv/export/mclaughlin/share_root/stressdevlab/GenR_derivatives/fmriprep/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_confounds = locate('sub-*confounds_regressors.tsv', root)\n",
    "found_rsbold = locate('sub-*MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(found_confounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/net/holynfs01/srv/export/mclaughlin/share_root/stressdevlab/GenR_derivatives/fmriprep/sub-1001/ses-1/func/sub-1001_ses-1_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_rsbold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds_filename = found_confounds\n",
    "#18 regressors are these 9, and their derivatives.\n",
    "motion_reg_colnames = ['csf', 'white_matter', 'global_signal', 'trans_x', 'trans_y', 'trans_z', 'rot_x' , 'rot_y', 'rot_z']\n",
    "#To compute spike regressors\n",
    "spikereg_colnames = ['dvars', 'framewise_displacement']\n",
    "deriv = True\n",
    "quad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/net/holynfs01/srv/export/mclaughlin/share_root/stressdevlab/GenR_derivatives/fmriprep/sub-1001/ses-1/func/sub-1001_ses-1_task-rest_desc-confounds_regressors.tsv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confounds_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csf',\n",
       " 'white_matter',\n",
       " 'global_signal',\n",
       " 'trans_x',\n",
       " 'trans_y',\n",
       " 'trans_z',\n",
       " 'rot_x',\n",
       " 'rot_y',\n",
       " 'rot_z',\n",
       " 'dvars',\n",
       " 'framewise_displacement']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_reg_colnames + spikereg_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_derivs = True\n",
    "use_quads = False\n",
    "dvar_reg = True\n",
    "displace_reg = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds = pd.read_csv(confounds_filename, sep = '\\t').reindex(columns = motion_reg_colnames + spikereg_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds_motion_reg = confounds[motion_reg_colnames]\n",
    "confounds_spikereg = confounds[spikereg_colnames]\n",
    "\n",
    "if use_derivs == True:\n",
    "    deriv = np.diff(confounds_motion_reg, n=1, axis=0)\n",
    "    deriv_df = pd.DataFrame(np.insert(arr=confounds_deriv, obj=0, values=0, axis=0), \n",
    "                            columns=[s + '_deriv' for s in confounds_motion_reg.columns])\n",
    "    confounds_motion_all = pd.concat([confounds_motion_reg, deriv_df], axis=1)\n",
    "else:\n",
    "    confounds_motion_all = confounds_motion_reg\n",
    "\n",
    "if use_quads == True:\n",
    "    quads_df = confounds_motion_all.apply(np.square)\n",
    "    quads_df.columns = [s + '_sq' for s in quads_df.columns]\n",
    "    confounds_motion_all = pd.concat([confounds_motion_all, quads_df], axis=1)\n",
    "\n",
    "#Compute some more columns for the confounds df\n",
    "#from https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLMotionOutliers:\n",
    "#--thresh=<val>       specify absolute threshold value (otherwise use box-plot cutoff = P75 + 1.5*IQR)\n",
    "\n",
    "spikes=pd.Series([0]*confounds_spikereg.shape[0])\n",
    "\n",
    "if dvar_reg == False and displace_reg == False:\n",
    "    raise Exception('Must include at least one spike regressor option.')\n",
    "\n",
    "if dvar_reg == True:\n",
    "    dvar_outlier_boundry = percentile(confounds_spikereg.loc[1:, 'dvars'], q = [75]) + 1.5*iqr(confounds_spikereg.loc[1:, 'dvars'])\n",
    "    spikes = spikes + confounds_spikereg['dvars'].apply(lambda dvar: 1 if dvar > dvar_outlier_boundry else 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     0\n",
       "20     0\n",
       "21     1\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "150    0\n",
       "151    0\n",
       "152    0\n",
       "153    0\n",
       "154    0\n",
       "155    0\n",
       "156    0\n",
       "157    0\n",
       "158    0\n",
       "159    0\n",
       "160    0\n",
       "161    0\n",
       "162    0\n",
       "163    0\n",
       "164    0\n",
       "165    0\n",
       "166    0\n",
       "167    0\n",
       "168    0\n",
       "169    0\n",
       "170    0\n",
       "171    0\n",
       "172    0\n",
       "173    0\n",
       "174    0\n",
       "175    0\n",
       "176    0\n",
       "177    0\n",
       "178    0\n",
       "179    0\n",
       "Length: 180, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import Node, Workflow\n",
    "\n",
    "# it's important to\n",
    "# pass filenames to Nodes as absolute paths\n",
    "from os.path import abspath\n",
    "from nipype.interfaces import afni\n",
    "import nibabel as nib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = abspath(found_rsbold)\n",
    "number_trs = nib.load(in_file).shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the 3dDespike node, which will be connected to the 3dDeconvolve node\n",
    "despike = Node(afni.Despike(in_file = in_file), name = \"despike\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for getting the results of 1dBport into a data frame\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bandpass regressors\n",
    "result = subprocess.run(['1dBport', '-nodata', str(number_trs), '2', '-band', '0.01', '.08', '-invert', '-nozero'], stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "b = StringIO(result.stdout.decode('utf-8'))\n",
    "\n",
    "df = pd.read_csv(b, sep='\\s+', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_root]",
   "language": "python",
   "name": "conda-env-my_root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
